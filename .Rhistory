for(i in seq_along(fnFs3)) {
system2(cutadapt, args = c(R1.flags, R2.flags, "-n", 2, # -n 2 required to remove FWD and REV from reads
"-o", fnFs.cut3[i], "-p", fnRs.cut3[i], # output files
"-m", 215, "-M", 285, # min/Max length cutoff
fnFs.filtN3[i], fnRs.filtN3[i])) # input files
}
rbind(FWD.ForwardReads = sapply(FWD.orients, primerHits, fn = fnFs.cut3[[1]]),
FWD.ReverseReads = sapply(FWD.orients, primerHits, fn = fnRs.cut3[[1]]),
REV.ForwardReads = sapply(REV.orients, primerHits, fn = fnFs.cut3[[1]]),
REV.ReverseReads = sapply(REV.orients, primerHits, fn = fnRs.cut3[[1]]))
for(i in seq_along(fnFs4)) {
system2(cutadapt, args = c(R1.flags, R2.flags, "-n", 2, # -n 2 required to remove FWD and REV from reads
"-o", fnFs.cut4[i], "-p", fnRs.cut4[i], # output files
"-m", 215, "-M", 285, # min/Max length cutoff
fnFs.filtN4[i], fnRs.filtN4[i])) # input files
}
rbind(FWD.ForwardReads = sapply(FWD.orients, primerHits, fn = fnFs.cut4[[1]]),
FWD.ReverseReads = sapply(FWD.orients, primerHits, fn = fnRs.cut4[[1]]),
REV.ForwardReads = sapply(REV.orients, primerHits, fn = fnFs.cut4[[1]]),
REV.ReverseReads = sapply(REV.orients, primerHits, fn = fnRs.cut4[[1]]))
for(i in seq_along(fnFs5)) {
system2(cutadapt, args = c(R1.flags, R2.flags, "-n", 2, # -n 2 required to remove FWD and REV from reads
"-o", fnFs.cut5[i], "-p", fnRs.cut5[i], # output files
"-m", 215, "-M", 285, # min/Max length cutoff
fnFs.filtN5[i], fnRs.filtN5[i])) # input files
}
rbind(FWD.ForwardReads = sapply(FWD.orients, primerHits, fn = fnFs.cut5[[1]]),
FWD.ReverseReads = sapply(FWD.orients, primerHits, fn = fnRs.cut5[[1]]),
REV.ForwardReads = sapply(REV.orients, primerHits, fn = fnFs.cut5[[1]]),
REV.ReverseReads = sapply(REV.orients, primerHits, fn = fnRs.cut5[[1]]))
for(i in seq_along(fnFs6)) {
system2(cutadapt, args = c(R1.flags, R2.flags, "-n", 2, # -n 2 required to remove FWD and REV from reads
"-o", fnFs.cut6[i], "-p", fnRs.cut6[i], # output files
"-m", 215, "-M", 285, # min/Max length cutoff
fnFs.filtN6[i], fnRs.filtN6[i])) # input files
}
rbind(FWD.ForwardReads = sapply(FWD.orients, primerHits, fn = fnFs.cut6[[1]]),
FWD.ReverseReads = sapply(FWD.orients, primerHits, fn = fnRs.cut6[[1]]),
REV.ForwardReads = sapply(REV.orients, primerHits, fn = fnFs.cut6[[1]]),
REV.ReverseReads = sapply(REV.orients, primerHits, fn = fnRs.cut6[[1]]))
.cran_packages <- c("tidyverse", "gridExtra")
.bioc_packages <- c("dada2")
.inst <- .cran_packages %in% installed.packages()
if(any(!.inst)) {
install.packages(.cran_packages[!.inst])
}
.inst <- .bioc_packages %in% installed.packages()
if(any(!.inst)) {
BiocManager::install(.bioc_packages[!.inst], quietly = FALSE)
}
# Load packages into session, and print package version
sapply(c(.cran_packages, .bioc_packages), require, character.only = TRUE)
# Setting seed for reproducibility
set.seed(100)
# File parsing
path_1 <- "../data/16S-fastq/RUN1_AE51B/cutadapt"
fastqFs_1 <- sort(list.files(path_1, pattern="_R1_001.fastq.gz", full.names = TRUE))
fastqRs_1 <- sort(list.files(path_1, pattern="_R2_001.fastq.gz", full.names = TRUE))
if(length(fastqFs_1) != length(fastqRs_1)) stop("Forward and reverse files do not match.")
pf1 <- plotQualityProfile(fastqFs_1[1:6])
pf1
pr1 <- plotQualityProfile(fastqRs_1[1:6])
pr1
fastqFs_1 <- sort(list.files(path_1, pattern="_R1_001.fastq.gz", full.names = F))
fastqRs_1 <- sort(list.files(path_1, pattern="_R2_001.fastq.gz", full.names = F))
if(length(fastqFs_1) != length(fastqRs_1)) stop("Forward and reverse files do not match.")
filtpath_1 <- file.path(path_1, "filtered") # Filtered forward files go into the pathF/filtered/ subdirectory
# Filtering: THESE PARAMETERS ARE RUN SPECIFIC DATASETS
out_1 <- filterAndTrim(fwd=file.path(path_1, fastqFs_1), filt=file.path(filtpath_1, fastqFs_1),
rev=file.path(path_1, fastqRs_1), filt.rev=file.path(filtpath_1, fastqRs_1),
truncLen=c(200,180),
maxEE=5,
rm.phix=TRUE,
compress=TRUE, verbose=TRUE, multithread=TRUE)
head(out_1)
# File parsing
path_2 <- "../data/16S-fastq/RUN2_AH2MV/cutadapt"
fastqFs_2 <- sort(list.files(path_2, pattern="_R1_001.fastq.gz", full.names = T))
fastqRs_2 <- sort(list.files(path_2, pattern="_R2_001.fastq.gz", full.names = T))
if(length(fastqFs_2) != length(fastqRs_2)) stop("Forward and reverse files do not match.")
pf2 <- plotQualityProfile(fastqFs_2[1:6])
pf2
pr2 <- plotQualityProfile(fastqRs_2[1:6])
pr2
# Filtering: Optomized for Run2 Sequences
filtpath_2 <- file.path(path_2, "filtered") # Filtered forward files go into the pathF/filtered/ subdirectory
fastqFs_2 <- sort(list.files(path_2, pattern="_R1_001.fastq.gz", full.names = F))
fastqRs_2 <- sort(list.files(path_2, pattern="_R2_001.fastq.gz", full.names = F))
# Filtering: Optomized for Run2 Sequences
out_2 <- filterAndTrim(fwd=file.path(path_2, fastqFs_2), filt=file.path(filtpath_2, fastqFs_2),
rev=file.path(path_2, fastqRs_2), filt.rev=file.path(filtpath_2, fastqRs_2),
truncLen=c(200,180),
maxEE=5,
rm.phix=TRUE,
compress=TRUE, verbose=TRUE, multithread=TRUE)
head(out_2)
# File parsing
path_3 <- "../data/16S-fastq/RUN3_AHFM2/cutadapt"
fastqFs_3 <- sort(list.files(path_3, pattern="_R1_001.fastq.gz", full.names = T))
fastqRs_3 <- sort(list.files(path_3, pattern="_R2_001.fastq.gz", full.names = T))
if(length(fastqFs_3) != length(fastqRs_3)) stop("Forward and reverse files do not match.")
pf3 <- plotQualityProfile(fastqFs_3[1:6])
pf3
pr3 <- plotQualityProfile(fastqRs_3[1:6])
pr3
filtpath_3 <- file.path(path_3, "filtered") # Filtered forward files go into the pathF/filtered/ subdirectory
fastqFs_3 <- sort(list.files(path_3, pattern="_R1_001.fastq.gz", full.names = F))
fastqRs_3 <- sort(list.files(path_3, pattern="_R2_001.fastq.gz", full.names = F))
# Filtering: THESE PARAMETERS ARENT OPTIMAL FOR ALL DATASETS
out_3 <- filterAndTrim(fwd=file.path(path_3, fastqFs_3), filt=file.path(filtpath_3, fastqFs_3),
rev=file.path(path_3, fastqRs_3), filt.rev=file.path(filtpath_3, fastqRs_3),
truncLen=c(220,180),
maxEE=5,
rm.phix=TRUE,
compress=TRUE, verbose=TRUE, multithread=TRUE)
head(out_3)
# File parsing
path_4 <- "../data/16S-fastq/RUN4_AN2A6/cutadapt"
fastqFs_4 <- sort(list.files(path_4, pattern="_R1_001.fastq.gz", full.names = T))
fastqRs_4 <- sort(list.files(path_4, pattern="_R2_001.fastq.gz", full.names = T))
if(length(fastqFs_4) != length(fastqRs_4)) stop("Forward and reverse files do not match.")
pf4 <- plotQualityProfile(fastqFs_4[1:6])
pf4
pr4 <- plotQualityProfile(fastqRs_4[1:6])
pr4
filtpath_4 <- file.path(path_4, "filtered") # Filtered forward files go into the pathF/filtered/ subdirectory
fastqFs_4 <- sort(list.files(path_4, pattern="_R1_001.fastq.gz", full.names = F))
fastqRs_4 <- sort(list.files(path_4, pattern="_R2_001.fastq.gz", full.names = F))
# Filtering: THESE PARAMETERS ARENT OPTIMAL FOR ALL DATASETS
out_4 <- filterAndTrim(fwd=file.path(path_4, fastqFs_4), filt=file.path(filtpath_4, fastqFs_4),
rev=file.path(path_4, fastqRs_4), filt.rev=file.path(filtpath_4, fastqRs_4),
truncLen=c(220,180),
maxEE=5,
rm.phix=TRUE,
compress=TRUE, verbose=TRUE, multithread=TRUE)
head(out_4)
# File parsing
path_5 <- "../data/16S-fastq/RUN5_CCVK7/cutadapt"
fastqFs_5 <- sort(list.files(path_5, pattern="_R1_001.fastq.gz", full.names = T))
fastqRs_5 <- sort(list.files(path_5, pattern="_R2_001.fastq.gz", full.names = T))
if(length(fastqFs_5) != length(fastqRs_5)) stop("Forward and reverse files do not match.")
pf5 <- plotQualityProfile(fastqFs_5[1:6])
pf5
pr5 <- plotQualityProfile(fastqRs_5[1:6])
pr5
fastqFs_5
fastqRs_5
filtpath_5 <- file.path(path_5, "filtered") # Filtered forward files go into the pathF/filtered/ subdirectory
fastqFs_5 <- sort(list.files(path_5, pattern="_R1_001.fastq.gz", full.names = F))
fastqRs_5 <- sort(list.files(path_5, pattern="_R2_001.fastq.gz", full.names = F))
# Filtering: THESE PARAMETERS ARE RUN SPECIFIC DATASETS
out_5 <- filterAndTrim(fwd=file.path(path_5, fastqFs_5), filt=file.path(filtpath_5, fastqFs_5),
rev=file.path(path_5, fastqRs_5), filt.rev=file.path(filtpath_5, fastqRs_5),
truncLen=c(220,180),
maxEE=5,
rm.phix=TRUE,
compress=TRUE, verbose=TRUE, multithread=TRUE)
out_5
# File parsing
path_6 <- "../data/16S-fastq/RUN6_BWTM2/cutadapt"
fastqFs_6 <- sort(list.files(path_6, pattern="_R1_001.fastq.gz", full.names = TRUE))
fastqRs_6 <- sort(list.files(path_6, pattern="_R2_001.fastq.gz", full.names = TRUE))
if(length(fastqFs_6) != length(fastqRs_6)) stop("Forward and reverse files do not match.")
pf6 <- plotQualityProfile(fastqFs_6[1:6])
pf6
pr6 <- plotQualityProfile(fastqRs_6[1:6])
pr6
fastqFs_6 <- sort(list.files(path_6, pattern="_R1_001.fastq.gz", full.names = F))
fastqRs_6 <- sort(list.files(path_6, pattern="_R2_001.fastq.gz", full.names = F))
if(length(fastqFs_6) != length(fastqRs_6)) stop("Forward and reverse files do not match.")
filtpath_6 <- file.path(path_6, "filtered") # Filtered forward files go into the pathF/filtered/ subdirectory
# Filtering: THESE PARAMETERS ARE RUN SPECIFIC DATASETS
out_6 <- filterAndTrim(fwd=file.path(path_6, fastqFs_6), filt=file.path(filtpath_6, fastqFs_6),
rev=file.path(path_6, fastqRs_6), filt.rev=file.path(filtpath_6, fastqRs_6),
truncLen=c(220,180),
maxEE=5,
rm.phix=TRUE,
compress=TRUE, verbose=TRUE, multithread=TRUE)
head(out_6)
# File parsing
filtFs_1 <- list.files(filtpath_1, pattern="_R1_001.fastq.gz", full.names = TRUE)
filtRs_1 <- list.files(filtpath_1, pattern="_R2_001.fastq.gz", full.names = TRUE)
sampleNames_1 <- sapply(strsplit(basename(filtFs_1), "_"), `[`, 1) # Assumes filename = samplename_XXX.fastq.gz
sampleNamesR_1 <- sapply(strsplit(basename(filtRs_1), "_"), `[`, 1) # Assumes filename = samplename_XXX.fastq.gz
if(!identical(sampleNames_1, sampleNamesR_1)) stop("Forward and reverse files do not match.")
names(filtFs_1) <- sampleNames_1
names(filtRs_1) <- sampleNames_1
set.seed(100)
# Learn forward error rates
errF_1 <- learnErrors(filtFs_1, nbases=1e8, multithread=TRUE)
# Learn reverse error rates
errR_1 <- learnErrors(filtRs_1, nbases=1e8, multithread=TRUE)
# File parsing
filtFs_2 <- list.files(filtpath_2, pattern="_R1_001.fastq.gz", full.names = TRUE)
filtRs_2 <- list.files(filtpath_2, pattern="_R2_001.fastq.gz", full.names = TRUE)
sampleNames_2 <- sapply(strsplit(basename(filtFs_2), "_"), `[`, 1) # Assumes filename = samplename_XXX.fastq.gz
sampleNamesR_2 <- sapply(strsplit(basename(filtRs_2), "_"), `[`, 1) # Assumes filename = samplename_XXX.fastq.gz
if(!identical(sampleNames_2, sampleNamesR_2)) stop("Forward and reverse files do not match.")
names(filtFs_2) <- sampleNames_2
names(filtRs_2) <- sampleNames_2
set.seed(100)
# Learn forward error rates
errF_2 <- learnErrors(filtFs_2, nbases=1e8, multithread=TRUE)
# Learn reverse error rates
errR_2 <- learnErrors(filtRs_1, nbases=1e8, multithread=TRUE)
# File parsing
filtFs_3 <- list.files(filtpath_3, pattern="_R1_001.fastq.gz", full.names = TRUE)
filtRs_3 <- list.files(filtpath_3, pattern="_R2_001.fastq.gz", full.names = TRUE)
sampleNames_3 <- sapply(strsplit(basename(filtFs_3), "_"), `[`, 1) # Assumes filename = samplename_XXX.fastq.gz
sampleNamesR_3 <- sapply(strsplit(basename(filtRs_3), "_"), `[`, 1) # Assumes filename = samplename_XXX.fastq.gz
if(!identical(sampleNames_3, sampleNamesR_3)) stop("Forward and reverse files do not match.")
names(filtFs_3) <- sampleNames_3
names(filtRs_3) <- sampleNames_3
set.seed(100)
# Learn forward error rates
errF_3 <- learnErrors(filtFs_3, nbases=1e8, multithread=TRUE)
# Learn reverse error rates
errR_3 <- learnErrors(filtRs_3, nbases=1e8, multithread=TRUE)
# File parsing
filtFs_4 <- list.files(filtpath_4, pattern="_R1_001.fastq.gz", full.names = TRUE)
filtRs_4 <- list.files(filtpath_4, pattern="_R2_001.fastq.gz", full.names = TRUE)
sampleNames_4 <- sapply(strsplit(basename(filtFs_4), "_"), `[`, 1) # Assumes filename = samplename_XXX.fastq.gz
sampleNamesR_4 <- sapply(strsplit(basename(filtRs_4), "_"), `[`, 1) # Assumes filename = samplename_XXX.fastq.gz
if(!identical(sampleNames_4, sampleNamesR_4)) stop("Forward and reverse files do not match.")
names(filtFs_4) <- sampleNames_4
names(filtRs_4) <- sampleNames_4
set.seed(100)
# Learn forward error rates
errF_4 <- learnErrors(filtFs_4, nbases=1e8, multithread=TRUE)
# Learn reverse error rates
errR_4 <- learnErrors(filtRs_4, nbases=1e8, multithread=TRUE)
# File parsing
filtFs_5 <- list.files(filtpath_5, pattern="_R1_001.fastq.gz", full.names = TRUE)
filtRs_5 <- list.files(filtpath_5, pattern="_R2_001.fastq.gz", full.names = TRUE)
sampleNames_5 <- sapply(strsplit(basename(filtFs_5), "_"), `[`, 1) # Assumes filename = samplename_XXX.fastq.gz
sampleNamesR_5 <- sapply(strsplit(basename(filtRs_5), "_"), `[`, 1) # Assumes filename = samplename_XXX.fastq.gz
if(!identical(sampleNames_5, sampleNamesR_5)) stop("Forward and reverse files do not match.")
names(filtFs_5) <- sampleNames_5
names(filtRs_5) <- sampleNames_5
set.seed(100)
# Learn forward error rates
errF_5 <- learnErrors(filtFs_5, nbases=1e8, multithread=TRUE)
# Learn reverse error rates
errR_5 <- learnErrors(filtRs_5, nbases=1e8, multithread=TRUE)
# File parsing
filtFs_6 <- list.files(filtpath_6, pattern="_R1_001.fastq.gz", full.names = TRUE)
filtRs_6 <- list.files(filtpath_6, pattern="_R2_001.fastq.gz", full.names = TRUE)
sampleNames_6 <- sapply(strsplit(basename(filtFs_6), "_"), `[`, 1) # Assumes filename = samplename_XXX.fastq.gz
sampleNamesR_6 <- sapply(strsplit(basename(filtRs_6), "_"), `[`, 1) # Assumes filename = samplename_XXX.fastq.gz
if(!identical(sampleNames_6, sampleNamesR_6)) stop("Forward and reverse files do not match.")
names(filtFs_6) <- sampleNames_6
names(filtRs_6) <- sampleNames_6
set.seed(100)
# Learn forward error rates
errF_6 <- learnErrors(filtFs_6, nbases=1e8, multithread=TRUE)
# Learn reverse error rates
errR_6 <- learnErrors(filtRs_6, nbases=1e8, multithread=TRUE)
plotErrors(errF_1, nominalQ=TRUE)
plotErrors(errF_2, nominalQ=TRUE)
plotErrors(errF_3, nominalQ=TRUE)
plotErrors(errF_4, nominalQ=TRUE)
plotErrors(errF_5, nominalQ=TRUE)
plotErrors(errF_6, nominalQ=TRUE)
dadaFs_1 <- dada(filtFs_1, err=errF_1, multithread=TRUE)
dadaRs_1 <- dada(filtRs_1, err=errR_1, multithread=TRUE)
dadaFs_2 <- dada(filtFs_2, err=errF_2, multithread=TRUE)
dadaRs_2 <- dada(filtRs_2, err=errR_2, multithread=TRUE)
dadaFs_3 <- dada(filtFs_3, err=errF_3, multithread=TRUE)
dadaRs_3 <- dada(filtRs_3, err=errR_3, multithread=TRUE)
dadaFs_4 <- dada(filtFs_4, err=errF_4, multithread=TRUE)
dadaRs_4 <- dada(filtRs_4, err=errR_4, multithread=TRUE)
dadaFs_5 <- dada(filtFs_5, err=errF_5, multithread=TRUE)
dadaRs_5 <- dada(filtRs_5, err=errR_5, multithread=TRUE)
dadaFs_6 <- dada(filtFs_6, err=errF_6, multithread=TRUE)
dadaRs_6 <- dada(filtRs_6, err=errR_6, multithread=TRUE)
# Filter out all sequences not within length 245-255 bp, Target is 252bp, with added 10bo of length on either side
MINLEN <- 250
MAXLEN <- 256
mergers_1 <- mergePairs(dadaFs_1, filtFs_1, dadaRs_1, filtRs_1, verbose=TRUE)
# Inspect the merger data.frame from the first sample
head(mergers_1[[1]])
seqtab_1 <- makeSequenceTable(mergers_1)
seqtab_size_filt_1 <- seqtab_1[ ,nchar(colnames(seqtab_1)) %in% seq (MINLEN,MAXLEN)]
# Chimera Removal
seqtab_size_filt_nochim_1 <- removeBimeraDenovo(seqtab_size_filt_1, method="consensus", multithread=TRUE)
# Look at fraction of chimeras. Here, chimeras made up about 13.8% of the sequences, but that was only about 2% of total sequence reads
dim(seqtab_size_filt_1)
dim(seqtab_size_filt_nochim_1)
sum(seqtab_size_filt_nochim_1)/sum(seqtab_size_filt_1)
mergers_2 <- mergePairs(dadaFs_2, filtFs_2, dadaRs_2, filtRs_2, verbose=TRUE)
# Inspect the merger data.frame from the first sample
head(mergers_2[[1]])
seqtab_2 <- makeSequenceTable(mergers_2)
seqtab_size_filt_2 <- seqtab_2[ ,nchar(colnames(seqtab_2)) %in% seq (MINLEN,MAXLEN)]
# Chimera Removal
seqtab_size_filt_nochim_2 <- removeBimeraDenovo(seqtab_size_filt_2, method="consensus", multithread=TRUE)
# Look at fraction of chimeras. Here, chimeras made up about 13.8% of the sequences, but that was only about 2% of total sequence reads
dim(seqtab_size_filt_2)
dim(seqtab_size_filt_nochim_2)
sum(seqtab_size_filt_nochim_2)/sum(seqtab_size_filt_2)
mergers_3 <- mergePairs(dadaFs_3, filtFs_3, dadaRs_3, filtRs_3, verbose=TRUE)
# Inspect the merger data.frame from the first sample
head(mergers_3[[1]])
seqtab_3 <- makeSequenceTable(mergers_3)
seqtab_size_filt_3 <- seqtab_3[ ,nchar(colnames(seqtab_3)) %in% seq (MINLEN,MAXLEN)]
seqtab_size_filt_nochim_3 <- removeBimeraDenovo(seqtab_size_filt_3, method="consensus", multithread=TRUE)
#Look at fraction of chimeras. Here, chimeras made up about 13.8% of the sequences, but that was only about 3% of total sequence reads
dim(seqtab_size_filt_3)
dim(seqtab_size_filt_nochim_3)
sum(seqtab_size_filt_nochim_3)/sum(seqtab_size_filt_3)
mergers_4 <- mergePairs(dadaFs_4, filtFs_4, dadaRs_4, filtRs_4, verbose=TRUE)
# Inspect the merger data.frame from the first sample
head(mergers_4[[1]])
seqtab_4 <- makeSequenceTable(mergers_4)
seqtab_size_filt_4 <- seqtab_4[ ,nchar(colnames(seqtab_4)) %in% seq (MINLEN,MAXLEN)]
seqtab_size_filt_nochim_4 <- removeBimeraDenovo(seqtab_size_filt_4, method="consensus", multithread=TRUE)
#Look at fraction of chimeras. Here, chimeras made up about 14.8% of the sequences, but that was only about 4% of total sequence reads
dim(seqtab_size_filt_4)
dim(seqtab_size_filt_nochim_4)
sum(seqtab_size_filt_nochim_4)/sum(seqtab_size_filt_4)
mergers_5 <- mergePairs(dadaFs_5, filtFs_5, dadaRs_5, filtRs_5, verbose=TRUE)
# Inspect the merger data.frame from the first sample
head(mergers_5[[1]])
seqtab_5 <- makeSequenceTable(mergers_5)
seqtab_size_filt_5 <- seqtab_5[ ,nchar(colnames(seqtab_5)) %in% seq (MINLEN,MAXLEN)]
seqtab_size_filt_nochim_5 <- removeBimeraDenovo(seqtab_size_filt_5, method="consensus", multithread=TRUE)
#Look at fraction of chimeras. Here, chimeras made up about 15.8% of the sequences, but that was only about 5% of total sequence reads
dim(seqtab_size_filt_5)
dim(seqtab_size_filt_nochim_5)
sum(seqtab_size_filt_nochim_5)/sum(seqtab_size_filt_5)
mergers_6 <- mergePairs(dadaFs_6, filtFs_6, dadaRs_6, filtRs_6, verbose=TRUE)
# Inspect the merger data.frame from the first sample
head(mergers_6[[1]])
seqtab_6 <- makeSequenceTable(mergers_6)
seqtab_size_filt_6 <- seqtab_6[ ,nchar(colnames(seqtab_6)) %in% seq (MINLEN,MAXLEN)]
seqtab_size_filt_nochim_6 <- removeBimeraDenovo(seqtab_size_filt_6, method="consensus", multithread=TRUE)
#Look at fraction of chimeras. Here, chimeras made up about 15.8% of the sequences, but that was only about 5% of total sequence reads
dim(seqtab_size_filt_6)
dim(seqtab_size_filt_nochim_6)
sum(seqtab_size_filt_nochim_6)/sum(seqtab_size_filt_6)
getN <- function(x) sum(getUniques(x))
#Run1
track_1 <- cbind(out_1, sapply(dadaFs_1, getN), sapply(dadaRs_1, getN), sapply(mergers_1, getN), rowSums(seqtab_size_filt_nochim_1))
colnames(track_1) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nochim")
rownames(track_1) <- sampleNames_1
#Run2
track_2 <- cbind(out_2, sapply(dadaFs_2, getN), sapply(dadaRs_2, getN), sapply(mergers_2, getN), rowSums(seqtab_size_filt_nochim_2))
colnames(track_2) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nochim")
rownames(track_2) <- sampleNames_2
#Run3
track_3 <- cbind(out_3, sapply(dadaFs_3, getN), sapply(dadaRs_3, getN), sapply(mergers_3, getN), rowSums(seqtab_size_filt_nochim_3))
colnames(track_3) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nochim")
rownames(track_3) <- sampleNames_3
#Run4
track_4 <- cbind(out_4, sapply(dadaFs_4, getN), sapply(dadaRs_4, getN), sapply(mergers_4, getN), rowSums(seqtab_size_filt_nochim_4))
colnames(track_4) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nochim")
rownames(track_4) <- sampleNames_4
#Run5
track_5 <- cbind(out_5, sapply(dadaFs_5, getN), sapply(dadaRs_5, getN), sapply(mergers_5, getN), rowSums(seqtab_size_filt_nochim_5))
colnames(track_5) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nochim")
rownames(track_5) <- sampleNames_5
#Run6
track_6 <- cbind(out_6, sapply(dadaFs_6, getN), sapply(dadaRs_6, getN), sapply(mergers_6, getN), rowSums(seqtab_size_filt_nochim_6))
colnames(track_6) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nochim")
rownames(track_6) <- sampleNames_6
track_all <- rbind(track_1, track_2, track_3, track_4, track_5, track_6)
track_all <- as.data.frame(track_all)
track_all <- rownames_to_column(track_all, "sample")
colnames(track_all)
track_all <- track_all %>% mutate(perc_original_sequences = nochim/input*100)
write_csv(track_all, "../data/DADA2_Tracking_All_Runs.csv")
seqtab <- mergeSequenceTables(seqtab_size_filt_nochim_1,
seqtab_size_filt_nochim_2,
seqtab_size_filt_nochim_3,
seqtab_size_filt_nochim_4,
seqtab_size_filt_nochim_5,
seqtab_size_filt_nochim_6
)
dim(seqtab)
saveRDS(seqtab, "../data/seqtab.rds")
.cran_packages <- c("tidyverse")
.bioc_packages <- c("dada2")
.inst <- .cran_packages %in% installed.packages()
if(any(!.inst)) {
install.packages(.cran_packages[!.inst])
}
.inst <- .bioc_packages %in% installed.packages()
if(any(!.inst)) {
BiocManager::install(.bioc_packages[!.inst], quietly = FALSE)
}
# Load packages into session, and print package version
sapply(c(.cran_packages, .bioc_packages), require, character.only = TRUE)
seqtab <- readRDS(file = "16S_output/seqtab.rds")
# Assign taxonomy SILVA Train Set
# Change path of training set to wherever fasta file is located
tax_silva <- assignTaxonomy(seqtab, "~/Documents/MICaB/Hunter_Lab/taxonomyTrainingSets/silva_nr_v132_train_set.fa.gz", multithread=TRUE)
seqtab <- readRDS("16S_output/seqtab.rds")
View(seqtab)
.cran_packages <- c("tidyverse")
.bioc_packages <- c("dada2")
.inst <- .cran_packages %in% installed.packages()
if(any(!.inst)) {
install.packages(.cran_packages[!.inst])
}
.inst <- .bioc_packages %in% installed.packages()
if(any(!.inst)) {
BiocManager::install(.bioc_packages[!.inst], quietly = FALSE)
}
# Load packages into session, and print package version
sapply(c(.cran_packages, .bioc_packages), require, character.only = TRUE)
seqtab <- readRDS(file = "16S_output/seqtab.rds")
# Assign taxonomy SILVA Train Set
# Change path of training set to wherever fasta file is located
tax_silva <- assignTaxonomy(seqtab, "~/Documents/MICaB/Hunter_Lab/taxonomyTrainingSets/silva_nr_v132_train_set.fa.gz", multithread=TRUE)
.cran_packages <- c("tidyverse", "gridExtra", "ips")
.bioc_packages <- c("dada2", "phyloseq", "DECIPHER", "phangorn", "ShortRead")
.inst <- .cran_packages %in% installed.packages()
if(any(!.inst)) {
install.packages(.cran_packages[!.inst])
}
.inst <- .bioc_packages %in% installed.packages()
if(any(!.inst)) {
BiocManager::install(.bioc_packages[!.inst], quietly = FALSE)
}
# Load packages into session, and print package version
sapply(c(.cran_packages, .bioc_packages), require, character.only = TRUE)
set.seed(100)
seqtab <- readRDS(file = "../data/seqtab.rds")
# Assign taxonomy SILVA Train Set
# Change path of training set to wherever fasta file is located
tax_silva <- assignTaxonomy(seqtab, "~/Documents/MICaB/Hunter_Lab/taxonomyTrainingSets/silva_nr_v132_train_set.fa.gz", multithread=TRUE)
colnames(tax_silva) <- c("Kingdom", "Phylum", "Class", "Order", "Family", "Genus")
## Add species assignment to taxonomy table: https://benjjneb.github.io/dada2/assign.html#species-assignment
# Change path of training set to wherever fasta file is located
tax_species_silva <- addSpecies(tax_silva, "~/Documents/MICaB/Hunter_Lab/taxonomyTrainingSets/silva_species_assignment_v132.fa.gz",
verbose=TRUE,
allowMultiple = FALSE)
colnames(tax_species_silva)  <- c("Kingdom", "Phylum", "Class", "Order", "Family", "Genus", "Species")
unname(head(tax_species_silva))
## Add species assignment to taxonomy table: https://benjjneb.github.io/dada2/assign.html#species-assignment
tax_species_silva_HOMD <- addSpecies(tax_silva, "TaxonomyTrainingSets/HOMD_16S_rRNA_RefSeq_V15.1.p9_dada2_addspecies.fasta",
verbose=TRUE,
allowMultiple = FALSE)
colnames(tax_species_silva_HOMD) <- c("Kingdom", "Phylum", "Class", "Order", "Family", "Genus", "Species_HOMD")
unname(head(tax_species_silva_HOMD))
#make rownames for ASVs for each species level taxa table
tax_species_silva_df <- as.data.frame(tax_species_silva) %>%
rownames_to_column('ASV')
tax_species_silva_df[tax_species_silva_df == "cf."] <- NA
tax_species_silva_df[tax_species_silva_df == "sp."] <- NA
dim(tax_species_silva_df)
tax_species_silva_HOMD_df <- as.data.frame(tax_species_silva_HOMD) %>%
rownames_to_column('ASV')
tax_species_silva_HOMD_df[tax_species_silva_HOMD_df == "cf."] <- NA
tax_species_silva_HOMD_df[tax_species_silva_HOMD_df == "sp."] <- NA
dim(tax_species_silva_HOMD_df)
# Use a full join to keep all rows and all columns x and y; NA for not matching values.
# by is set to ASV, Kingdom, Phylum, Class, Order, Family, Genus, so the join must match on all these levels.
tax_species_silva_HOMD_df_join <- full_join(x = tax_species_silva_df,
y = tax_species_silva_HOMD_df,
by = c("ASV","Kingdom", "Phylum", "Class", "Order", "Family", "Genus"))
dim(tax_species_silva_HOMD_df_join)
tax_species_silva_HOMD_df_join <- tax_species_silva_HOMD_df_join %>%
mutate(DB = ifelse(!is.na(Species) & !is.na(Species_HOMD), "Both",
ifelse(!is.na(Species), "SILVA",
ifelse(!is.na(Species_HOMD), "HOMD", NA))))
HOMD <- filter(tax_species_silva_HOMD_df_join, DB == "HOMD")
HOMD
# If there is no species assignment in the Species_SILVA column, check the Species_HOMD column. If the Species_HOMD column says NA or sp. assign NA.
tax_species_silva_HOMD_df_join_newspecies <- tax_species_silva_HOMD_df_join %>%
mutate(SpeciesCombo = ifelse(!is.na(Species), as.character(Species), as.character(Species_HOMD))) %>%
select(ASV, Kingdom, Phylum, Class, Order, Family, Genus, SpeciesCombo, DB) %>%
dplyr::rename(Species = SpeciesCombo) %>%
column_to_rownames('ASV') %>%
as.matrix()
# Write to disk
saveRDS(tax_species_silva_HOMD_df_join_newspecies, "../data/tax_species_final_silva_HOMD.rds")
speciesCompare <- tax_species_silva_HOMD_df_join %>%
filter(is.na(Species) & !is.na(Species_HOMD))
dim(speciesCompare)
length(which(!is.na(tax_species_silva_df$Species)))
length(which(!is.na(tax_species_silva_HOMD_df$Species_HOMD)))
length(which(!is.na(tax_species_silva_HOMD_df_join$Species)))
length(which(!is.na(tax_species_silva_HOMD_df_join$Species_HOMD)))
.cran_packages <- c("tidyverse", "ips")
.bioc_packages <- c("dada2", "DECIPHER", "phangorn", "ShortRead")
.inst <- .cran_packages %in% installed.packages()
if(any(!.inst)) {
install.packages(.cran_packages[!.inst])
}
.inst <- .bioc_packages %in% installed.packages()
if(any(!.inst)) {
BiocManager::install(.bioc_packages[!.inst], quietly = FALSE)
}
# Load packages into session, and print package version
sapply(c(.cran_packages, .bioc_packages), require, character.only = TRUE)
# Setting seed for reproducibility
set.seed(12345)
seqtab <- readRDS("16S_output/seqtab.rds")
# seqtab is the sample:ASV table made in DADA2 - it should contain all samples and ASVs
seqs <- getSequences(seqtab)
names(seqs) <- seqs # This propogates the tip labels of the tree
alignment <- AlignSeqs(DNAStringSet(seqs), anchor=NA)
phang.align <- phyDat(as(alignment, "matrix"), type="DNA")
dm <- dist.ml(phang.align)
treeNJ <- NJ(dm)
fit = pml(treeNJ, data=phang.align)
fitGTR <- update(fit, k=4, inv=0.2)
fitGTR <- optim.pml(fitGTR, model="GTR", optInv=TRUE, optGamma=TRUE,
rearrangement = "stochastic", control = pml.control(trace = 0))
detach("package:phangorn", unload=TRUE)
saveRDS(fitGTR, "16S_output/fitGTR.rds")
