---
title: "16S Sequence Analysis of CRS and Healthy Sinus Samples"
Author: "Sarah Lucas"
---
# Description

This notebook is to document the identification and analysis of amplicon sequence variants (ASV) from 16S sequencing data isolated from CRS and non-CRS patient sinus mucus. This will be done using the DADA2 package 
* Publication: http://www.nature.com/nmeth/journal/v13/n7/full/nmeth.3869.html?foxtrotcallback=true
* DADA2 Github: https://benjjneb.github.io/dada2/tutorial.html). 

ASVs are inferred using the DADA2 error modeling for each sequencing run individually, as there may be run-specific errors present.

# DADA2 inference of ASVs
## Setup environment
```{r}
.cran_packages <- c("tidyverse", "gridExtra")
.bioc_packages <- c("dada2")

.inst <- .cran_packages %in% installed.packages()
if(any(!.inst)) {
   install.packages(.cran_packages[!.inst])
}
.inst <- .bioc_packages %in% installed.packages()
if(any(!.inst)) {
   BiocManager::install(.bioc_packages[!.inst], quietly = FALSE)
}
# Load packages into session, and print package version
sapply(c(.cran_packages, .bioc_packages), require, character.only = TRUE)

# Setting seed for reproducibility
set.seed(100)
```

# Reading in sequences, quality filtering and trimming.
## Run 1
```{r}
# File parsing
path_1 <- "../data/16S/fastq/RUN1_AE51B/cutadapt"
fastqFs_1 <- sort(list.files(path_1, pattern="_R1_001.fastq.gz", full.names = TRUE))
fastqRs_1 <- sort(list.files(path_1, pattern="_R2_001.fastq.gz", full.names = TRUE))
if(length(fastqFs_1) != length(fastqRs_1)) stop("Forward and reverse files do not match.")
```

```{r}
pf1 <- plotQualityProfile(fastqFs_1[1:6])
pf1
pr1 <- plotQualityProfile(fastqRs_1[1:6])
pr1
```
```{r}
fastqFs_1 <- sort(list.files(path_1, pattern="_R1_001.fastq.gz", full.names = F))
fastqRs_1 <- sort(list.files(path_1, pattern="_R2_001.fastq.gz", full.names = F))
if(length(fastqFs_1) != length(fastqRs_1)) stop("Forward and reverse files do not match.")

filtpath_1 <- file.path(path_1, "filtered") # Filtered forward files go into the pathF/filtered/ subdirectory
# Filtering: THESE PARAMETERS ARE RUN SPECIFIC DATASETS
out_1 <- filterAndTrim(fwd=file.path(path_1, fastqFs_1), filt=file.path(filtpath_1, fastqFs_1),
              rev=file.path(path_1, fastqRs_1), filt.rev=file.path(filtpath_1, fastqRs_1),
              truncLen=c(200,180), 
              maxEE=5,
              rm.phix=TRUE,
              compress=TRUE, verbose=TRUE, multithread=TRUE)
head(out_1)
```

## Run 2
```{r}
# File parsing
path_2 <- "../data/16S/fastq/RUN2_AH2MV/cutadapt"
fastqFs_2 <- sort(list.files(path_2, pattern="_R1_001.fastq.gz", full.names = T))
fastqRs_2 <- sort(list.files(path_2, pattern="_R2_001.fastq.gz", full.names = T))
if(length(fastqFs_2) != length(fastqRs_2)) stop("Forward and reverse files do not match.")
```
```{r}
pf2 <- plotQualityProfile(fastqFs_2[1:6])
pf2
pr2 <- plotQualityProfile(fastqRs_2[1:6])
pr2
```
```{r}
# Filtering: Optomized for Run2 Sequences
filtpath_2 <- file.path(path_2, "filtered") # Filtered forward files go into the pathF/filtered/ subdirectory
fastqFs_2 <- sort(list.files(path_2, pattern="_R1_001.fastq.gz", full.names = F))
fastqRs_2 <- sort(list.files(path_2, pattern="_R2_001.fastq.gz", full.names = F))
# Filtering: Optomized for Run2 Sequences
out_2 <- filterAndTrim(fwd=file.path(path_2, fastqFs_2), filt=file.path(filtpath_2, fastqFs_2),
              rev=file.path(path_2, fastqRs_2), filt.rev=file.path(filtpath_2, fastqRs_2),
              truncLen=c(200,180),
              maxEE=5,
              rm.phix=TRUE,
              compress=TRUE, verbose=TRUE, multithread=TRUE)

head(out_2)
```
## Run 3
```{r}
# File parsing
path_3 <- "../data/16S/fastq/RUN3_AHFM2/cutadapt"
fastqFs_3 <- sort(list.files(path_3, pattern="_R1_001.fastq.gz", full.names = T))
fastqRs_3 <- sort(list.files(path_3, pattern="_R2_001.fastq.gz", full.names = T))
if(length(fastqFs_3) != length(fastqRs_3)) stop("Forward and reverse files do not match.")

pf3 <- plotQualityProfile(fastqFs_3[1:6])
pf3
pr3 <- plotQualityProfile(fastqRs_3[1:6])
pr3
```
```{r}
filtpath_3 <- file.path(path_3, "filtered") # Filtered forward files go into the pathF/filtered/ subdirectory
fastqFs_3 <- sort(list.files(path_3, pattern="_R1_001.fastq.gz", full.names = F))
fastqRs_3 <- sort(list.files(path_3, pattern="_R2_001.fastq.gz", full.names = F))
# Filtering: THESE PARAMETERS ARENT OPTIMAL FOR ALL DATASETS
out_3 <- filterAndTrim(fwd=file.path(path_3, fastqFs_3), filt=file.path(filtpath_3, fastqFs_3),
              rev=file.path(path_3, fastqRs_3), filt.rev=file.path(filtpath_3, fastqRs_3),
              truncLen=c(220,180), 
              maxEE=5, 
              rm.phix=TRUE,
              compress=TRUE, verbose=TRUE, multithread=TRUE)
head(out_3)
```

## Run 4
```{r}
# File parsing
path_4 <- "../data/16S/fastq/RUN4_AN2A6/cutadapt"
fastqFs_4 <- sort(list.files(path_4, pattern="_R1_001.fastq.gz", full.names = T))
fastqRs_4 <- sort(list.files(path_4, pattern="_R2_001.fastq.gz", full.names = T))
if(length(fastqFs_4) != length(fastqRs_4)) stop("Forward and reverse files do not match.")

pf4 <- plotQualityProfile(fastqFs_4[1:6])
pf4
pr4 <- plotQualityProfile(fastqRs_4[1:6])
pr4
```

```{r}
filtpath_4 <- file.path(path_4, "filtered") # Filtered forward files go into the pathF/filtered/ subdirectory
fastqFs_4 <- sort(list.files(path_4, pattern="_R1_001.fastq.gz", full.names = F))
fastqRs_4 <- sort(list.files(path_4, pattern="_R2_001.fastq.gz", full.names = F))
# Filtering: THESE PARAMETERS ARENT OPTIMAL FOR ALL DATASETS
out_4 <- filterAndTrim(fwd=file.path(path_4, fastqFs_4), filt=file.path(filtpath_4, fastqFs_4),
              rev=file.path(path_4, fastqRs_4), filt.rev=file.path(filtpath_4, fastqRs_4),
              truncLen=c(220,180),
              maxEE=5,
              rm.phix=TRUE,
              compress=TRUE, verbose=TRUE, multithread=TRUE)
head(out_4)
```

## Run 5
```{r}
# File parsing
path_5 <- "../data/16S/fastq/RUN5_CCVK7/cutadapt"
fastqFs_5 <- sort(list.files(path_5, pattern="_R1_001.fastq.gz", full.names = T))
fastqRs_5 <- sort(list.files(path_5, pattern="_R2_001.fastq.gz", full.names = T))
if(length(fastqFs_5) != length(fastqRs_5)) stop("Forward and reverse files do not match.")

pf5 <- plotQualityProfile(fastqFs_5[1:6])
pf5
pr5 <- plotQualityProfile(fastqRs_5[1:6])
pr5

fastqFs_5
fastqRs_5
```

```{r}
filtpath_5 <- file.path(path_5, "filtered") # Filtered forward files go into the pathF/filtered/ subdirectory
fastqFs_5 <- sort(list.files(path_5, pattern="_R1_001.fastq.gz", full.names = F))
fastqRs_5 <- sort(list.files(path_5, pattern="_R2_001.fastq.gz", full.names = F))
# Filtering: THESE PARAMETERS ARE RUN SPECIFIC DATASETS
out_5 <- filterAndTrim(fwd=file.path(path_5, fastqFs_5), filt=file.path(filtpath_5, fastqFs_5),
              rev=file.path(path_5, fastqRs_5), filt.rev=file.path(filtpath_5, fastqRs_5),
              truncLen=c(220,180),
              maxEE=5, 
              rm.phix=TRUE,
              compress=TRUE, verbose=TRUE, multithread=TRUE)
out_5
```

## Run 6
```{r}
# File parsing
path_6 <- "../data/16S/fastq/RUN6_BWTM2/cutadapt"
fastqFs_6 <- sort(list.files(path_6, pattern="_R1_001.fastq.gz", full.names = TRUE))
fastqRs_6 <- sort(list.files(path_6, pattern="_R2_001.fastq.gz", full.names = TRUE))
if(length(fastqFs_6) != length(fastqRs_6)) stop("Forward and reverse files do not match.")
```

```{r}
pf6 <- plotQualityProfile(fastqFs_6[1:6])
pf6
pr6 <- plotQualityProfile(fastqRs_6[1:6])
pr6
```
```{r}
fastqFs_6 <- sort(list.files(path_6, pattern="_R1_001.fastq.gz", full.names = F))
fastqRs_6 <- sort(list.files(path_6, pattern="_R2_001.fastq.gz", full.names = F))
if(length(fastqFs_6) != length(fastqRs_6)) stop("Forward and reverse files do not match.")

filtpath_6 <- file.path(path_6, "filtered") # Filtered forward files go into the pathF/filtered/ subdirectory
# Filtering: THESE PARAMETERS ARE RUN SPECIFIC DATASETS
out_6 <- filterAndTrim(fwd=file.path(path_6, fastqFs_6), filt=file.path(filtpath_6, fastqFs_6),
              rev=file.path(path_6, fastqRs_6), filt.rev=file.path(filtpath_6, fastqRs_6),
              truncLen=c(220,180), 
              maxEE=5,
              rm.phix=TRUE,
              compress=TRUE, verbose=TRUE, multithread=TRUE)
head(out_6)
```
# Infer Sequence Variants
This should be run on a run-by-run basis as not all runs will have the same error profiles
## Run 1
```{r}
# File parsing
filtFs_1 <- list.files(filtpath_1, pattern="_R1_001.fastq.gz", full.names = TRUE)
filtRs_1 <- list.files(filtpath_1, pattern="_R2_001.fastq.gz", full.names = TRUE)
sampleNames_1 <- sapply(strsplit(basename(filtFs_1), "_"), `[`, 1) # Assumes filename = samplename_XXX.fastq.gz
sampleNamesR_1 <- sapply(strsplit(basename(filtRs_1), "_"), `[`, 1) # Assumes filename = samplename_XXX.fastq.gz
if(!identical(sampleNames_1, sampleNamesR_1)) stop("Forward and reverse files do not match.")
names(filtFs_1) <- sampleNames_1
names(filtRs_1) <- sampleNames_1
set.seed(100)
# Learn forward error rates
errF_1 <- learnErrors(filtFs_1, nbases=1e8, multithread=TRUE)
# Learn reverse error rates
errR_1 <- learnErrors(filtRs_1, nbases=1e8, multithread=TRUE)
```

## Run 2
```{r}
# File parsing
filtFs_2 <- list.files(filtpath_2, pattern="_R1_001.fastq.gz", full.names = TRUE)
filtRs_2 <- list.files(filtpath_2, pattern="_R2_001.fastq.gz", full.names = TRUE)
sampleNames_2 <- sapply(strsplit(basename(filtFs_2), "_"), `[`, 1) # Assumes filename = samplename_XXX.fastq.gz
sampleNamesR_2 <- sapply(strsplit(basename(filtRs_2), "_"), `[`, 1) # Assumes filename = samplename_XXX.fastq.gz
if(!identical(sampleNames_2, sampleNamesR_2)) stop("Forward and reverse files do not match.")
names(filtFs_2) <- sampleNames_2
names(filtRs_2) <- sampleNames_2
set.seed(100)
# Learn forward error rates
errF_2 <- learnErrors(filtFs_2, nbases=1e8, multithread=TRUE)
# Learn reverse error rates
errR_2 <- learnErrors(filtRs_1, nbases=1e8, multithread=TRUE)
```

## Run 3
```{r}
# File parsing
filtFs_3 <- list.files(filtpath_3, pattern="_R1_001.fastq.gz", full.names = TRUE)
filtRs_3 <- list.files(filtpath_3, pattern="_R2_001.fastq.gz", full.names = TRUE)
sampleNames_3 <- sapply(strsplit(basename(filtFs_3), "_"), `[`, 1) # Assumes filename = samplename_XXX.fastq.gz
sampleNamesR_3 <- sapply(strsplit(basename(filtRs_3), "_"), `[`, 1) # Assumes filename = samplename_XXX.fastq.gz
if(!identical(sampleNames_3, sampleNamesR_3)) stop("Forward and reverse files do not match.")
names(filtFs_3) <- sampleNames_3
names(filtRs_3) <- sampleNames_3
set.seed(100)
# Learn forward error rates
errF_3 <- learnErrors(filtFs_3, nbases=1e8, multithread=TRUE)
# Learn reverse error rates
errR_3 <- learnErrors(filtRs_3, nbases=1e8, multithread=TRUE)
```

## Run 4
```{r}
# File parsing
filtFs_4 <- list.files(filtpath_4, pattern="_R1_001.fastq.gz", full.names = TRUE)
filtRs_4 <- list.files(filtpath_4, pattern="_R2_001.fastq.gz", full.names = TRUE)
sampleNames_4 <- sapply(strsplit(basename(filtFs_4), "_"), `[`, 1) # Assumes filename = samplename_XXX.fastq.gz
sampleNamesR_4 <- sapply(strsplit(basename(filtRs_4), "_"), `[`, 1) # Assumes filename = samplename_XXX.fastq.gz
if(!identical(sampleNames_4, sampleNamesR_4)) stop("Forward and reverse files do not match.")
names(filtFs_4) <- sampleNames_4
names(filtRs_4) <- sampleNames_4
set.seed(100)
# Learn forward error rates
errF_4 <- learnErrors(filtFs_4, nbases=1e8, multithread=TRUE)
# Learn reverse error rates
errR_4 <- learnErrors(filtRs_4, nbases=1e8, multithread=TRUE)
```

## Run 5
```{r}
# File parsing
filtFs_5 <- list.files(filtpath_5, pattern="_R1_001.fastq.gz", full.names = TRUE)
filtRs_5 <- list.files(filtpath_5, pattern="_R2_001.fastq.gz", full.names = TRUE)
sampleNames_5 <- sapply(strsplit(basename(filtFs_5), "_"), `[`, 1) # Assumes filename = samplename_XXX.fastq.gz
sampleNamesR_5 <- sapply(strsplit(basename(filtRs_5), "_"), `[`, 1) # Assumes filename = samplename_XXX.fastq.gz
if(!identical(sampleNames_5, sampleNamesR_5)) stop("Forward and reverse files do not match.")
names(filtFs_5) <- sampleNames_5
names(filtRs_5) <- sampleNames_5
set.seed(100)
# Learn forward error rates
errF_5 <- learnErrors(filtFs_5, nbases=1e8, multithread=TRUE)
# Learn reverse error rates
errR_5 <- learnErrors(filtRs_5, nbases=1e8, multithread=TRUE)
```

## Run 6
```{r}
# File parsing
filtFs_6 <- list.files(filtpath_6, pattern="_R1_001.fastq.gz", full.names = TRUE)
filtRs_6 <- list.files(filtpath_6, pattern="_R2_001.fastq.gz", full.names = TRUE)
sampleNames_6 <- sapply(strsplit(basename(filtFs_6), "_"), `[`, 1) # Assumes filename = samplename_XXX.fastq.gz
sampleNamesR_6 <- sapply(strsplit(basename(filtRs_6), "_"), `[`, 1) # Assumes filename = samplename_XXX.fastq.gz
if(!identical(sampleNames_6, sampleNamesR_6)) stop("Forward and reverse files do not match.")
names(filtFs_6) <- sampleNames_6
names(filtRs_6) <- sampleNames_6
set.seed(100)
# Learn forward error rates
errF_6 <- learnErrors(filtFs_6, nbases=1e8, multithread=TRUE)
# Learn reverse error rates
errR_6 <- learnErrors(filtRs_6, nbases=1e8, multithread=TRUE)
```

Let's look at the error profiles for each of the dada2 runs
```{r}
plotErrors(errF_1, nominalQ=TRUE)
plotErrors(errF_2, nominalQ=TRUE)
plotErrors(errF_3, nominalQ=TRUE)
plotErrors(errF_4, nominalQ=TRUE)
plotErrors(errF_5, nominalQ=TRUE)
plotErrors(errF_6, nominalQ=TRUE)
```

# Sample Inference
apply the core inference algorithm to the filtered and trimmed sequence data
## Run1
```{r}
dadaFs_1 <- dada(filtFs_1, err=errF_1, multithread=TRUE)
dadaRs_1 <- dada(filtRs_1, err=errR_1, multithread=TRUE)
```
## Run2
```{r}
dadaFs_2 <- dada(filtFs_2, err=errF_2, multithread=TRUE)
dadaRs_2 <- dada(filtRs_2, err=errR_2, multithread=TRUE)
```
## Run3
```{r}
dadaFs_3 <- dada(filtFs_3, err=errF_3, multithread=TRUE)
dadaRs_3 <- dada(filtRs_3, err=errR_3, multithread=TRUE)
```
## Run4
```{r}
dadaFs_4 <- dada(filtFs_4, err=errF_4, multithread=TRUE)
dadaRs_4 <- dada(filtRs_4, err=errR_4, multithread=TRUE)
```
## Run5
```{r}
dadaFs_5 <- dada(filtFs_5, err=errF_5, multithread=TRUE)
dadaRs_5 <- dada(filtRs_5, err=errR_5, multithread=TRUE)
```
## Run6
```{r}
dadaFs_6 <- dada(filtFs_6, err=errF_6, multithread=TRUE)
dadaRs_6 <- dada(filtRs_6, err=errR_6, multithread=TRUE)
```

# Merge sequences and make tables
```{r}
# Filter out all sequences not within length 245-255 bp, Target is 252bp, with added 10bo of length on either side
MINLEN <- 215
MAXLEN <- 275
```

## Run 1
```{r}
mergers_1 <- mergePairs(dadaFs_1, filtFs_1, dadaRs_1, filtRs_1, verbose=TRUE)
# Inspect the merger data.frame from the first sample
head(mergers_1[[1]])
seqtab_1 <- makeSequenceTable(mergers_1)
seqtab_size_filt_1 <- seqtab_1[ ,nchar(colnames(seqtab_1)) %in% seq (MINLEN,MAXLEN)]
# Chimera Removal
seqtab_size_filt_nochim_1 <- removeBimeraDenovo(seqtab_size_filt_1, method="consensus", multithread=TRUE)
# Look at fraction of chimeras. Here, chimeras made up about 13.8% of the sequences, but that was only about 2% of total sequence reads
dim(seqtab_size_filt_1)
dim(seqtab_size_filt_nochim_1)
sum(seqtab_size_filt_nochim_1)/sum(seqtab_size_filt_1)
```

## Run 2
```{r}
mergers_2 <- mergePairs(dadaFs_2, filtFs_2, dadaRs_2, filtRs_2, verbose=TRUE)
# Inspect the merger data.frame from the first sample
head(mergers_2[[1]])
seqtab_2 <- makeSequenceTable(mergers_2)
seqtab_size_filt_2 <- seqtab_2[ ,nchar(colnames(seqtab_2)) %in% seq (MINLEN,MAXLEN)]
# Chimera Removal
seqtab_size_filt_nochim_2 <- removeBimeraDenovo(seqtab_size_filt_2, method="consensus", multithread=TRUE)
# Look at fraction of chimeras. Here, chimeras made up about 13.8% of the sequences, but that was only about 2% of total sequence reads
dim(seqtab_size_filt_2)
dim(seqtab_size_filt_nochim_2)
sum(seqtab_size_filt_nochim_2)/sum(seqtab_size_filt_2)
```

## Run 3
```{r}
mergers_3 <- mergePairs(dadaFs_3, filtFs_3, dadaRs_3, filtRs_3, verbose=TRUE)
# Inspect the merger data.frame from the first sample
head(mergers_3[[1]])
seqtab_3 <- makeSequenceTable(mergers_3)
seqtab_size_filt_3 <- seqtab_3[ ,nchar(colnames(seqtab_3)) %in% seq (MINLEN,MAXLEN)]
seqtab_size_filt_nochim_3 <- removeBimeraDenovo(seqtab_size_filt_3, method="consensus", multithread=TRUE)
#Look at fraction of chimeras. Here, chimeras made up about 13.8% of the sequences, but that was only about 3% of total sequence reads
dim(seqtab_size_filt_3)
dim(seqtab_size_filt_nochim_3)
sum(seqtab_size_filt_nochim_3)/sum(seqtab_size_filt_3)
```

## Run 4
```{r}
mergers_4 <- mergePairs(dadaFs_4, filtFs_4, dadaRs_4, filtRs_4, verbose=TRUE)
# Inspect the merger data.frame from the first sample
head(mergers_4[[1]])
seqtab_4 <- makeSequenceTable(mergers_4)
seqtab_size_filt_4 <- seqtab_4[ ,nchar(colnames(seqtab_4)) %in% seq (MINLEN,MAXLEN)]
seqtab_size_filt_nochim_4 <- removeBimeraDenovo(seqtab_size_filt_4, method="consensus", multithread=TRUE)
#Look at fraction of chimeras. Here, chimeras made up about 14.8% of the sequences, but that was only about 4% of total sequence reads
dim(seqtab_size_filt_4)
dim(seqtab_size_filt_nochim_4)
sum(seqtab_size_filt_nochim_4)/sum(seqtab_size_filt_4)
```

## Run 5
```{r}
mergers_5 <- mergePairs(dadaFs_5, filtFs_5, dadaRs_5, filtRs_5, verbose=TRUE)
# Inspect the merger data.frame from the first sample
head(mergers_5[[1]])
seqtab_5 <- makeSequenceTable(mergers_5)
seqtab_size_filt_5 <- seqtab_5[ ,nchar(colnames(seqtab_5)) %in% seq (MINLEN,MAXLEN)]
seqtab_size_filt_nochim_5 <- removeBimeraDenovo(seqtab_size_filt_5, method="consensus", multithread=TRUE)
#Look at fraction of chimeras. Here, chimeras made up about 15.8% of the sequences, but that was only about 5% of total sequence reads
dim(seqtab_size_filt_5)
dim(seqtab_size_filt_nochim_5)
sum(seqtab_size_filt_nochim_5)/sum(seqtab_size_filt_5)
```

## Run 6
```{r}
mergers_6 <- mergePairs(dadaFs_6, filtFs_6, dadaRs_6, filtRs_6, verbose=TRUE)
# Inspect the merger data.frame from the first sample
head(mergers_6[[1]])
seqtab_6 <- makeSequenceTable(mergers_6)
seqtab_size_filt_6 <- seqtab_6[ ,nchar(colnames(seqtab_6)) %in% seq (MINLEN,MAXLEN)]
seqtab_size_filt_nochim_6 <- removeBimeraDenovo(seqtab_size_filt_6, method="consensus", multithread=TRUE)
#Look at fraction of chimeras. Here, chimeras made up about 15.8% of the sequences, but that was only about 5% of total sequence reads
dim(seqtab_size_filt_6)
dim(seqtab_size_filt_nochim_6)
sum(seqtab_size_filt_nochim_6)/sum(seqtab_size_filt_6)
```

# Track Reads through pipeline (come back to this. Have to make for each run)
```{r}
getN <- function(x) sum(getUniques(x))
#Run1
track_1 <- cbind(out_1, sapply(dadaFs_1, getN), sapply(dadaRs_1, getN), sapply(mergers_1, getN), rowSums(seqtab_size_filt_nochim_1))
colnames(track_1) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nochim")
rownames(track_1) <- sampleNames_1

#Run2
track_2 <- cbind(out_2, sapply(dadaFs_2, getN), sapply(dadaRs_2, getN), sapply(mergers_2, getN), rowSums(seqtab_size_filt_nochim_2))
colnames(track_2) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nochim")
rownames(track_2) <- sampleNames_2

#Run3
track_3 <- cbind(out_3, sapply(dadaFs_3, getN), sapply(dadaRs_3, getN), sapply(mergers_3, getN), rowSums(seqtab_size_filt_nochim_3))
colnames(track_3) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nochim")
rownames(track_3) <- sampleNames_3

#Run4
track_4 <- cbind(out_4, sapply(dadaFs_4, getN), sapply(dadaRs_4, getN), sapply(mergers_4, getN), rowSums(seqtab_size_filt_nochim_4))
colnames(track_4) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nochim")
rownames(track_4) <- sampleNames_4

#Run5
track_5 <- cbind(out_5, sapply(dadaFs_5, getN), sapply(dadaRs_5, getN), sapply(mergers_5, getN), rowSums(seqtab_size_filt_nochim_5))
colnames(track_5) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nochim")
rownames(track_5) <- sampleNames_5

#Run6
track_6 <- cbind(out_6, sapply(dadaFs_6, getN), sapply(dadaRs_6, getN), sapply(mergers_6, getN), rowSums(seqtab_size_filt_nochim_6))
colnames(track_6) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nochim")
rownames(track_6) <- sampleNames_6

track_all <- rbind(track_1, track_2, track_3, track_4, track_5, track_6)
track_all <- as.data.frame(track_all)
track_all <- rownames_to_column(track_all, "sample")
colnames(track_all)
track_all <- track_all %>% mutate(perc_original_sequences = nochim/input*100)
```
```{r}
write_csv(track_all, "16S_output/DADA2_Tracking_All_Runs.csv")
```

# Combine all sequence tables
```{r}
seqtab <- mergeSequenceTables(seqtab_size_filt_nochim_1,
                              seqtab_size_filt_nochim_2, 
                              seqtab_size_filt_nochim_3,
                              seqtab_size_filt_nochim_4,
                              seqtab_size_filt_nochim_5,
                              seqtab_size_filt_nochim_6
                              )
dim(seqtab)
saveRDS(seqtab, "16S_output/seqtab.rds")
```
