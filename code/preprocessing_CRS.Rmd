 ---
title: "Filtering of Samples and Taxa by prevalence and abundance"
author: "Sarah Lucas"
---
# Purpose:

This notebook is to document the preprocessing of ASVs in the CRS 16S dataset. Goals are to filter out samples with very low read coverage (<2000 reads). Filter out very low abundance organisms for use in downstream analyses.


# Setup
```{r}
.cran_packages <- c("tidyverse","gridExtra", "devtools", 
                    "adaptiveGPCA", "ade4", "vegan", 
                    "devtools", "ggthemes", "naniar", 
                    "scales", "extrafont", "data.table",
                    "ggpubr")
.bioc_packages <- c("phyloseq", "BiocStyle","Biobase")

# Install CRAN packages (if not already installed)
.inst <- .cran_packages %in% installed.packages()
if (any(!.inst)){
  install.packages(.cran_packages[!.inst],repos = "http://cran.rstudio.com/")
}

.inst <- .bioc_packages %in% installed.packages()
if (any(!.inst)){
   BiocManager::install(.bioc_packages[!.inst], quietly = FALSE)
}

# Load packages into session, and print package version
sapply(c(.cran_packages, .bioc_packages), require, character.only = TRUE)
sapply(c(.cran_packages, .bioc_packages), package.version)
```

# Import Data
Load in all components created in the DADA2 analysis and the sample sheet
```{r}
samdf <- readRDS("../data/samdf_CRS.rds")
samdf <- data.frame(samdf)
rownames(samdf) <- samdf$SAMPLE_NAME #because R - dplyr will not like making rownames, but it's fine for now.
# seqtab is the sample:ASV table made in DADA2 - it should contain all samples and ASVs
# Filter out samples that are CF positive for this analysis
seqtab <- readRDS("16S_output/seqtab.rds")
# Table with all ASVs and assigned taxonomy using the SILVA database (Greengenes and RDP also available)
taxtab <- readRDS("16S_output/tax_species_final_silva_HOMD.rds")
# Phylogenetic tree made using DECIPHER and Phangorn - import object and pull tree from the fitGTR
fitGTR <- readRDS("16S_output/fitGTR.rds")
```
# Make Phyloseq Object
```{r}
PHYSEQ <- phyloseq(otu_table(seqtab, taxa_are_rows=FALSE), 
               sample_data(samdf), 
               tax_table(taxtab),
               phy_tree(fitGTR$tree)
)
PHYSEQ
```
## Adjust taxonomy levels
Add a new taxonomy level called TaxName, which ensures that no ASV is NA in downstream plots
```{r}
tax.PHYSEQ <-  data.frame(tax_table(PHYSEQ)) %>%
  rownames_to_column('ASV') %>%
  #Now getting into formatting the taxa so it looks nice and informative in plots
  mutate(Genus_Species = ifelse(!is.na(Species), 
                                str_c(Genus, Species, sep = " "), #Use option for SILVA database
                                #as.character(Species), #use option for RefSeq-RDP database
                                as.character(Genus))) %>%
  mutate(Genus_Species2 = ifelse(!is.na(Genus_Species), as.character(Genus_Species), as.character(Family))) %>%
  mutate(Genus_Species3 = ifelse(!is.na(Genus_Species2), as.character(Genus_Species2), as.character(Order))) %>%
  mutate(Genus_Species4 = ifelse(!is.na(Genus_Species3), as.character(Genus_Species3), as.character(Class))) %>%
  mutate(TaxName = ifelse(!is.na(Genus_Species4), as.character(Genus_Species4), as.character(Phylum)))
# Get rid of any extra notation in the taxonomy names.
tax.PHYSEQ <- data.frame(lapply(tax.PHYSEQ, function(x) {
  gsub("_[0-9]", "", x)
}))
tax.PHYSEQ <- tax.PHYSEQ %>%
  select(ASV, Kingdom, Phylum, Class, Order, Family, Genus, Species, Genus_Species2, TaxName, DB) %>%
  column_to_rownames('ASV') %>%
  as.matrix()
tax_table(PHYSEQ) <- tax.PHYSEQ
PHYSEQ
```

```{r}
sample_names(PHYSEQ)
```


## Filter out control samples and enrichment samples
```{r}
# Just get the FESS sinus samples
CRS <- subset_samples(PHYSEQ, SAMPLE_OR_CONTROL == "sample" #&
                        #SEQ_RUN_NAME_SHORT !="AE51B" # Sequences are of poor quality
                      )
CRS

CTRL <- subset_samples(PHYSEQ, SAMPLE_TYPE == "control")
CTRL
```
## Remove any seqeunces that don't belong to any samples and/or have no counts
```{r}
MINREADS <- 0
CRS0 <- filter_taxa(CRS, function(x) sum(x) > MINREADS, TRUE)
CRS0

CTRL <- filter_taxa(CTRL, function(x) sum(x) > MINREADS, TRUE)
CTRL
```
# Read Summary
## Assessing sample read coverage
```{r}
sdt <- data.table(as(sample_data(CRS0), "data.frame"),
                 TotalReads = sample_sums(CRS0), keep.rownames = TRUE)
setnames(sdt, "rn", "SAMPLE_ID")
pSeqDepth <- ggplot(sdt, aes(TotalReads)) + geom_histogram() + ggtitle("Sequencing Depth")
pSeqDepth
```
There are many samples with very low sequence depth, and a few with very high.
```{r}
pSeqDepth + facet_wrap(~DIAG_CRS) +
  ggtitle("Sequencing depth by sample type")
```
This is a skewed dataset that has many samples with low coverage. Both the CRS and Non-CRS sample groups take the same shape. Next, some preprocessing steps to get rid of ambiguous taxa and very low abundance phyla.
Summary of read depth:
```{r}
summary(sample_sums(CRS0))
```

## Preliminary Preprocessing
Look at the range of sequences using summary and sample_sums
```{r}
summary(sample_sums(CRS0))
which(!rowSums(otu_table(CRS0)) > 0)
summary(sample_sums(CTRL))
which(!rowSums(otu_table(CTRL)) > 0)
```
See which samples fall below 2000 reads and remove them from the dataset
```{r}
which(!rowSums(otu_table(CRS0)) > 2000)
seqThreshold <- 2000
CRS1 <- prune_samples(sample_sums(CRS0) > seqThreshold, CRS0)
CRS1
CRS1 <- filter_taxa(CRS1, function(x) sum(x) > MINREADS, TRUE)
CRS1
```
filtering at 2000 reads removes 22 samples from analysis

# Preprocessing

## Supervised Prevalence Filtering
Filter out any taxa that have an unassigned phylum - those aren't really useful to us. At this step, also remove ASVs that are associated with Chloroplast/Mitochondrial 16S.
```{r}
#Only want Bacterial Seqs, no chloroplast DNA, no mitochondrial DNA
filterKingdom = c("Archaea","Eukaryota")  
filterOrder = "Chloroplast" ##Chloroplast DNA
filterFamily = "Mitochondria" ## Mitochonidrial DNA

# Create table, number of features for each phyla
phylum_numbers <- data.frame(table(tax_table(CRS1)[, "Phylum"], exclude = NULL))
phylum_numbers
#filter features with an ambiguous phylum annotation.
CRS.pv.1 <- subset_taxa(CRS1, 
                        !is.na(Phylum) & !Phylum %in% c("", "uncharacterized","Unknown_Phylum") & 
                          !Kingdom %in% filterKingdom &
                          !Order %in% filterOrder & 
                          !Family %in% filterFamily)
CRS.pv.1
```
75 ASVs did not have a phylum assignment, or were associated with Chloroplast/mitochondria

A useful next step is to explore feature prevalence in the dataset, which we will define here as the number of samples in which a taxa appears at least once.
```{r}
# Compute prevalence of each feature, store as data.frame
prevdf = apply(X = otu_table(CRS.pv.1),
               MARGIN = ifelse(taxa_are_rows(CRS.pv.1), yes = 1, no = 2),
               FUN = function(x){sum(x > 0)})
# Add taxonomy and total read counts to this data.frame
prevdf = data.frame(Prevalence = prevdf,
                    TotalAbundance = taxa_sums(CRS.pv.1),
                    tax_table(CRS.pv.1))
```
Take a look graphically at the distribution of taxa among the different phyla:
```{r}
# Subset to the remaining phyla after initial filtering
prevdf.pv.phylum = subset(prevdf, Phylum %in% get_taxa_unique(CRS.pv.1, "Phylum"))
ggplot(prevdf.pv.phylum, aes(TotalAbundance, Prevalence / nsamples(CRS.pv.1),color=Phylum)) +
  # Include a guess for filtering parameter at 0.02
  geom_hline(yintercept = 0.02, alpha = 0.5, linetype = 2) + geom_point(size = 2, alpha = 0.7) +
  scale_x_log10() +  xlab("Total Abundance") + ylab("Prevalence [Frac. Samples]") + theme(text = element_text(size=10)) +
  facet_wrap(~Phylum) + theme(legend.position="none")
```

Are there phyla that are comprised of mostly low-prevalence features? Compute the total and average prevalences of the features in each phylum:
```{r}
#just look at phylum
prevdf.phylum <- plyr::ddply(prevdf, "Phylum", function(df1){cbind(mean(df1$Prevalence),sum(df1$Prevalence))})
colnames(prevdf.phylum)[2] <- "mean_feature_prevalence"
colnames(prevdf.phylum)[3] <- "total_feature_prevalence"
prevdf.phylum
```
Yes. Looks like there are some phyla that have quite low prevalence. Let's filter out any features belonging to phyla that have an average prevalence of just 1, or have features seen less than 10 times in the dataset:
```{r}
prevdf.phylum.filt <- filter(prevdf.phylum, mean_feature_prevalence <= 1.012097 | total_feature_prevalence < 10)
prevdf.phylum.filt
```
Remove the features belonging to these phyla in prevdf.phylum.filt from the dataset, creating CRS.pv.2
```{r}
# Filter low prevalence samples (supervised - you made this decision by looking at your data)
# Define phyla to filter - Here I have chosen those phyla that have an average prevalence of 1 OR have a total number of features less than 10.
filterPhyla = unique(prevdf.phylum.filt$Phylum)
filterPhyla
# Filter entries with unidentified Phylum.
CRS.pv.2 <- subset_taxa(CRS.pv.1, !Phylum %in% filterPhyla)
CRS.pv.2
```
Save this object as the minimally filtered dataset. Different applications may require different levels of filtering taxa after this step. Up to this point, the removal of taxa has been conservative.
```{r}
saveRDS(CRS.pv.2, "16S_output/phyloseq_supervised_filt.rds")
```


### Data Summary: Taxa Abundance 
## Assessing taxa prevalence
Prevalence is defined here as the number of times an OTU is observed at least once. That is, it is the number of samples in which each OTU was non-zero. I find this to be a more useful filtering and diagnostic criteria.
TotalAbundance here means the number of time a feature (ASV) was seen - just sum of the counts for each row.

```{r}
# Compute prevalence of each feature, store as data.frame
prevdf0 = apply(X = otu_table(CRS.pv.2),
               MARGIN = ifelse(taxa_are_rows(CRS.pv.2), yes = 1, no = 2),
               FUN = function(x){sum(x > 0)})
# Add taxonomy and total read counts to this data.frame
prevdf0 = data.frame(Prevalence = prevdf0,
                    TotalCounts = taxa_sums(CRS.pv.2),
                    tax_table(CRS.pv.2))
```
Plot the prevalence as a histogram
```{r}
ggplot(prevdf0, aes(Prevalence)) + 
  geom_histogram() + 
  ggtitle("Histogram of Taxa Prevalence")
```

# Unsupervised Prevalence Filtering

The previous filtering steps are considered supervised, because they relied on prior information that is external to this experiment (a taxonomic reference database). This next filtering step is completely unsupervised, relying only on the data in this experiment, and a parameter that we will choose after exploring the data. Thus, this filtering step can be applied even in settings where taxonomic annotation is unavailable or unreliable.

First, explore the relationship of prevalence and total read count for each feature. Sometimes this reveals outliers that should probably be removed, and also provides insight into the ranges of either feature that might be useful. This aspect depends quite a lot on the experimental design and goals of the downstream inference, so keep these in mind. It may even be the case that different types of downstream inference require different choices here. There is no reason to expect ahead of time that a single filtering workflow is appropriate for all analyses.

## ASV Prevalence Summary
```{r}
tdt = data.table(tax_table(CRS.pv.2),
                 TotalCounts = taxa_sums(CRS.pv.2),
                 OTU = taxa_names(CRS.pv.2))
ggplot(tdt, aes(TotalCounts)) + 
  geom_histogram() + 
  ggtitle("Histogram of Total Counts")
```
There are many low abundance ASVs that dominate the datatset.
```{r}
# taxa cumulative sum
taxcumsum = tdt[, .N, by = TotalCounts]
setkey(taxcumsum, TotalCounts)
taxcumsum[, CumSum := cumsum(N)]
# Define the plot
pCumSum = ggplot(taxcumsum, aes(TotalCounts, CumSum)) + 
  geom_point() +
  xlab("Filtering Threshold, Minimum Total Counts") +
  ylab("OTUs Filtered") +
  ggtitle("OTUs that would be filtered vs. the minimum count threshold")
pCumSum
```
```{r}
# Zoom-in
pCumSum + xlim(0, 100)
```
Get Average Relative abundances:
```{r}
CRS.pv.2.prop <- transform_sample_counts(CRS.pv.2, function(x) x/sum(x) * 100)
CRS.pv.2.prop.melt <- psmelt(CRS.pv.2.prop) %>%
  #filter(Abundance > 0) %>%
  group_by(OTU) %>%
  dplyr::summarize(avgRelAbun = mean(Abundance))
dim(CRS.pv.2.prop.melt)
```

```{r}
# Compute prevalence of each feature, store as data.frame
prevdf2 = apply(X = otu_table(CRS.pv.2), #CRS.pv.2.taxname
               MARGIN = ifelse(taxa_are_rows(CRS.pv.2), yes = 1, no = 2),
               FUN = function(x){sum(x > 0)})
# Add taxonomy and total read counts to this data.frame
prevdf2 = data.frame(Prevalence = prevdf2,
                    TotalAbundance = taxa_sums(CRS.pv.2),
                    tax_table(CRS.pv.2))  %>%
  rownames_to_column("ASV") %>%
  mutate(TotalPercent = round(TotalAbundance/sum(TotalAbundance) * 100, 4)) %>%
  left_join(CRS.pv.2.prop.melt, by = c("ASV" = "OTU")) %>%
  select(Prevalence, TotalAbundance, TotalPercent, avgRelAbun, DB, TaxName, everything())
```
```{r}
# convert dataframe to data.table
prevdt2 <- as.data.table(prevdf2)
```
Plot the cumulative sum at each level of prevalence filtering
```{r}
# taxa cumulative sum
prevcumsum = prevdt2[, .N, by = Prevalence]
setkey(prevcumsum, Prevalence)
prevcumsum[, CumSum := cumsum(N)]
pPrevCumSum = ggplot(prevcumsum, aes(Prevalence, CumSum)) + 
  geom_point() +
  xlab("Filtering Threshold, Prevalence") +
  ylab("OTUs Filtered") +
  ggtitle("OTUs that would be filtered vs. the minimum count threshold")
pPrevCumSum
```
Prevalence vs. Total Count Scatter Plot
```{r}
ggplot(prevdt2, aes(Prevalence, TotalAbundance)) + 
  geom_point(size = 2, alpha = 0.75) + 
  scale_y_log10() #+
  #scale_x_continuous(limits = c(0,20))
```
Prevalence vs. Count Scatter Plot - Phylum level
```{r}
# Subset to the remaining phyla after initial filtering
ggplot(prevdf2, aes(TotalAbundance, Prevalence / nsamples(CRS.pv.2),color=Phylum)) +
  # Include a guess for filtering parameter at 0.02
  geom_hline(yintercept = 0.02, alpha = 0.5, linetype = 2) + geom_point(size = 2, alpha = 0.7) +
  scale_x_log10() +  xlab("Total Abundance") + ylab("Prevalence [Frac. Samples]") + theme(text = element_text(size=10)) +
  facet_wrap(~Phylum) + theme(legend.position="none")
```

## Prevalence-Abundance based ASV filtering
Filtering thresholds
```{r}
#  Define prevalence threshold 
prevalenceThreshold =  1 # number of samples
abundanceThreshold = .01 # This is a percentage number is 1e-4
```

Which taxa would be filtered out at a prevalence of 1 and a mean relative abundance greater than .001%
```{r}
prevdf2Filt <- filter(prevdf2, Prevalence >= prevalenceThreshold, avgRelAbun > abundanceThreshold)
dim(prevdf2Filt)
keepTaxa <- unique(prevdf2Filt$ASV)

prevdf2thrown <- prevdf2 %>%
  filter(!ASV %in% keepTaxa)
dim(prevdf2thrown)
```

#Now get rid of any taxa that still are not present in greater than two samples. (For whatever reason, there will be taxa that don't belong to any samples still in the dataset)
```{r}
CRS.unsuper <- prune_taxa(keepTaxa, CRS.pv.2)
CRS.unsuper
```

Take a final look at taxa prevalence and abundance distribution
```{r}
# Compute prevalence of each feature, store as data.frame
prevdf.pv.unsuper = apply(X = otu_table(CRS.unsuper),
               MARGIN = ifelse(taxa_are_rows(CRS.unsuper), yes = 1, no = 2),
               FUN = function(x){sum(x > 0)})
# Add taxonomy and total read counts to this data.frame
prevdf.pv.unsuper = data.frame(Prevalence = prevdf.pv.unsuper,
                    TotalAbundance = taxa_sums(CRS.unsuper),
                    tax_table(CRS.unsuper)) #%>%
  #rownames_to_column("ASV") %>%
  #mutate(TotalPercent = round(TotalAbundance/sum(TotalAbundance) * 100, 4)) %>%
  #left_join(CRS.unsuper.melt, by = c("ASV" = "OTU")) %>%
  #column_to_rownames("ASV") %>%
  #select(Prevalence, TotalAbundance, TotalPercent, avgRelAbun, DB, TaxName, everything())
```

Post-supervised filtering distribution of taxa prevalence and abundance:
```{r}
# Subset to the remaining phyla after initial filtering
ggplot(prevdf.pv.unsuper, aes(TotalAbundance, Prevalence / nsamples(CRS.unsuper),color=Phylum)) +
  # Include a guess for filtering parameter at 0.02
  geom_hline(yintercept = 0.02, alpha = 0.5, linetype = 2) + geom_point(size = 2, alpha = 0.7) +
  scale_x_log10() +  xlab("Total Abundance") + ylab("Prevalence [Frac. Samples]") + theme(text = element_text(size=10)) +
  facet_wrap(~Phylum) + theme(legend.position="none")
```
```{r}
saveRDS(CRS.unsuper, "16S_output/phyloseq_unsupervised_filt.rds")
```

Make a rarified dataset to test with different analyses
Rarefy Even Depth to the median. Use this dataset to test different analyses for the impact of read depth. So far there looks to be no great difference in downstream plots. Using log transformed rarified data in the ordination analysis does diminish the variance described on the first axis, but there is still a signal associated with the presence of Bacteroidetes, just not as pronounced. Many of the samples cluster more closely with the firmicutes signal.
```{r}
CRS.unsuper.rare <- rarefy_even_depth(CRS.unsuper, 
                                           sample.size = 2000, 
                                           rngseed = 032020, 
                                           replace = FALSE, 
                                           trimOTUs = TRUE, 
                                           verbose = TRUE)
CRS.unsuper.rare
```
```{r}
saveRDS(CRS.unsuper.rare, "16S_output/phyloseq_unsupervised_filtered_rare.rds")
```
